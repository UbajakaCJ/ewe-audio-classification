## ewe-audio-classification
# __TechCabal Ewè Audio Translation Challenge__

Can you build a model to recognise Ewè commands from audio samples?

### __Description__

In many parts of the world, navigating public spaces remains a significant challenge for visually impaired individuals. The ability to accurately interpret and respond to spoken directions supports their independence and safety. This challenge aims to develop language models capable of recognising basic directional words in Ewe, a language spoken in parts of West Africa. This challenge not only addresses a pressing social issue but also highlights the importance of linguistic diversity in AI development.

The objective of this hackathon is to create machine learning models that can accurately classify audio recordings of basic directional commands in Ewè: "up," "down," "stop," "go," "left," "right," "yes," and "no."

The solutions will be used in a navigation voice assistant for visually impaired individuals who speak Ewè. By focusing on this specific use case, the challenge underscores the potential of AI for social good, particularly in underrepresented African languages.

Challenge link: https://zindi.africa/competitions/techcabal-ewe-audio-translation-challenge 


